{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install sinch\n",
    "!pip install azure.cognitiveservices.vision.customvision\n",
    "!pip install --upgrade azure-cognitiveservices-vision-customvision\n",
    "!pip install azure-identity\n",
    "!pip install azure-storage-blob azure-identity\n",
    "!pip install azure-storage-blob[aio]\n",
    "!pip install azure-storage-blob azure-mgmt-storage\n",
    "!pip install azure-storage-blob\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import os, time, uuid\n",
    "import cv2\n",
    "from sinch import Client\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.storage.blob.aio import BlobServiceClient, BlobClient, ContainerClient\n",
    "from azure.storage.blob import PublicAccess\n",
    "import asyncio\n",
    "import os\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.storage.blob.aio import BlobServiceClient, BlobClient, ContainerClient\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, PublicAccess\n",
    "import numpy as np\n",
    "import io\n",
    "import asyncio\n",
    "import os\n",
    "import uuid\n",
    "from azure.storage.blob import BlobBlock, StandardBlobTier\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.storage.blob.aio import BlobServiceClient, ContainerClient, BlobClient\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure custom CV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"\" #model endpoint\n",
    "prediction_key = \"\" #model key\n",
    "project_id = \"\" #project id\n",
    "publish_iteration_name = \"\" #iteration/model name\n",
    "iteration_id='' #iteration/model id\n",
    "\n",
    "\n",
    "# trained endpoint that can be used to make a prediction\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)\n",
    "\n",
    "def prediction(image):\n",
    "    classes=[]\n",
    "    with open(os.path.join (image), \"rb\") as image_contents:\n",
    "        results = predictor.detect_image(\n",
    "            project_id, publish_iteration_name, image_contents.read())\n",
    "\n",
    "        for prediction in results.predictions:\n",
    "            if prediction.probability >= 0.86:  # Set the threshold to 80%\n",
    "                classes.append(prediction.tag_name)\n",
    "                print(\"\\t\" + prediction.tag_name + \": {0:.2f}% bbox.left = {1:.2f}, bbox.top = {2:.2f}, bbox.width = {3:.2f}, bbox.height = {4:.2f}\".format(prediction.probability * 100, prediction.bounding_box.left, prediction.bounding_box.top, prediction.bounding_box.width, prediction.bounding_box.height))\n",
    "    print(\"\\n\")\n",
    "    unique_classes = set(classes)\n",
    "    return unique_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinch SMS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sms():\n",
    "    sinch_client = Client(\n",
    "        key_id=\"\",\n",
    "        key_secret=\"\",\n",
    "        project_id=\"\"\n",
    "    )\n",
    "\n",
    "    send_batch_response = sinch_client.sms.batches.send(\n",
    "        body=\"\",\n",
    "        to=[\"\"],\n",
    "        from_=\"\",\n",
    "        delivery_report=\"none\"\n",
    "    )\n",
    "\n",
    "    print(send_batch_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BlobSamples(object):\n",
    "\n",
    "    # <Snippet_upload_blob_file>\n",
    "    async def upload_blob_file(self, blob_service_client: BlobServiceClient, container_name: 'video'):\n",
    "        container_client = blob_service_client.get_container_client(container=container_name)\n",
    "        with open(file=os.path.join(directory, filename), mode=\"rb\") as data:\n",
    "            blob_client = await container_client.upload_blob(name=\"image1.jpg\", data=data, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tis code\n",
    "async def main():\n",
    "    sample = BlobSamples()\n",
    "\n",
    "    # TODO: Replace <storage-account-name> with your actual storage account name\n",
    "    account_url = \"\"\n",
    "    credential = ''\n",
    "\n",
    "    async with BlobServiceClient(account_url, credential=credential) as blob_service_client:\n",
    "        await sample.upload_blob_file(blob_service_client, \"video\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0) #chnage the camera/webcam accordingly\n",
    "global base64Frames\n",
    "base64Frames = []\n",
    "\n",
    "if not vid.isOpened():\n",
    "    print(\"Error: Unable to open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to capture frame.\")\n",
    "        break\n",
    "\n",
    "    # Process the frame here (e.g., resize, convert color)\n",
    "    processed_frame = frame  # Replace this with your processing logic\n",
    "\n",
    "    _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "    base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "    \n",
    "    cv2.imshow('frame', processed_frame)\n",
    "    # Save the processed frame as an image file\n",
    "    if len(base64Frames) % 30 == 0: #decided to do every 30th frame due to hardware restriction and to hasten prediction time\n",
    "        \n",
    "        directory = \"image\"\n",
    "\n",
    "# Specify the filename of your image\n",
    "        filename = \"temp_frame.jpg\"\n",
    "\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Combine the directory and filename to get the full path of the image\n",
    "        image_path = os.path.join(directory, filename)\n",
    "\n",
    "        cv2.imwrite(image_path, processed_frame)\n",
    "                \n",
    "        unique_classes = prediction(image_path)\n",
    "    \n",
    "        print(\"Classes detected:\", unique_classes)\n",
    "        print('\\n')\n",
    "        \n",
    "        if 'patient' and 'nurse'  in unique_classes:\n",
    "            print('No SMS')\n",
    "            \n",
    "        elif 'patient' in unique_classes:               \n",
    "            await main()\n",
    "            sms()\n",
    "            time.sleep(1)\n",
    "\n",
    "    if len(base64Frames) % 400 == 0:\n",
    "        del base64Frames[:100]\n",
    "    \n",
    "    elif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('nlp_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a780a905b0354456775c7958e4048b32e96aba80b49847c2bc874b4b77b80e15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
