  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import os, time, uuid\n",
    "import cv2\n",
    "from sinch import Client\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.storage.blob.aio import BlobServiceClient, BlobClient, ContainerClient\n",
    "from azure.storage.blob import PublicAccess\n",
    "import asyncio\n",
    "import os\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.storage.blob.aio import BlobServiceClient, BlobClient, ContainerClient\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, PublicAccess\n",
    "import numpy as np\n",
    "import io\n",
    "import asyncio\n",
    "import os\n",
    "import uuid\n",
    "from azure.storage.blob import BlobBlock, StandardBlobTier\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.storage.blob.aio import BlobServiceClient, ContainerClient, BlobClient\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"https://aiepcustom-prediction.cognitiveservices.azure.com/\" #model endpoint\n",
    "prediction_key = \"092eec11dfde4b4d8fb81b7505ad36b1\" #model key\n",
    "project_id = \"94bd8b74-8c22-4f32-9536-40addd03b945\" #project id\n",
    "publish_iteration_name = \"Iteration1\" #iteration/model name\n",
    "iteration_id='c940cb86-4a0a-4fbf-9b23-b36f952f5cb3' #iteration/model id\n",
    "\n",
    "\n",
    "# trained endpoint that can be used to make a prediction\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)\n",
    "\n",
    "def prediction(image):\n",
    "    classes=[]\n",
    "    with open(os.path.join (image), \"rb\") as image_contents:\n",
    "        results = predictor.detect_image(\n",
    "            project_id, publish_iteration_name, image_contents.read())\n",
    "\n",
    "        for prediction in results.predictions:\n",
    "            if prediction.probability >= 0.86:  # Set the threshold to 80%\n",
    "                classes.append(prediction.tag_name)\n",
    "                print(\"\\t\" + prediction.tag_name + \": {0:.2f}% bbox.left = {1:.2f}, bbox.top = {2:.2f}, bbox.width = {3:.2f}, bbox.height = {4:.2f}\".format(prediction.probability * 100, prediction.bounding_box.left, prediction.bounding_box.top, prediction.bounding_box.width, prediction.bounding_box.height))\n",
    "    print(\"\\n\")\n",
    "    unique_classes = set(classes)\n",
    "    return unique_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sms():\n",
    "    sinch_client = Client(\n",
    "        key_id=\"0e850afa-a134-42c5-ad0d-521e4f05acec\",\n",
    "        key_secret=\"rritjfPiSK-vaDfJRo4Ek2MwR.\",\n",
    "        project_id=\"a0b6337f-308c-4752-aa69-8e64e7ce31ee\"\n",
    "    )\n",
    "\n",
    "    send_batch_response = sinch_client.sms.batches.send(\n",
    "        body=\"Elderly detected out of boundary. Click here to see the image: https://playbackaiep.blob.core.windows.net/video/image1.jpg\",\n",
    "        to=[\"+6598967886\"],\n",
    "        from_=\"+447520662385\",\n",
    "        delivery_report=\"none\"\n",
    "    )\n",
    "\n",
    "    print(send_batch_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BlobSamples(object):\n",
    "\n",
    "    # <Snippet_upload_blob_file>\n",
    "    async def upload_blob_file(self, blob_service_client: BlobServiceClient, container_name: 'video'):\n",
    "        container_client = blob_service_client.get_container_client(container=container_name)\n",
    "        with open(file=os.path.join(directory, filename), mode=\"rb\") as data:\n",
    "            blob_client = await container_client.upload_blob(name=\"image1.jpg\", data=data, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tis code\n",
    "async def main():\n",
    "    sample = BlobSamples()\n",
    "\n",
    "    # TODO: Replace <storage-account-name> with your actual storage account name\n",
    "    account_url = \"https://playbackaiep.blob.core.windows.net\"\n",
    "    credential = 'n5ZXNLlZb21/r15DBNNDgLn2gX9WBK1/6S19oyAlue6OCJV++xZL5flw6aLE7bz0+yFkF8AJKH+4+AStN4kb5g=='\n",
    "\n",
    "    async with BlobServiceClient(account_url, credential=credential) as blob_service_client:\n",
    "        await sample.upload_blob_file(blob_service_client, \"video\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classes detected: set()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classes detected: set()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classes detected: set()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classes detected: set()\n",
      "\n",
      "\n",
      "\tpatient: 88.73% bbox.left = 0.01, bbox.top = 0.04, bbox.width = 0.48, bbox.height = 0.96\n",
      "\n",
      "\n",
      "Classes detected: {'patient'}\n",
      "\n",
      "\n",
      "SendSMSBatchResponse(id='01HQ0GC477BFJ6X66XT1PQ14C5', to=['6598967886'], from_='447520662385', body='Elderly detected out of boundary. Click here to see the image: https://playbackaiep.blob.core.windows.net/video/image1.jpg', delivery_report='none', cancelled=None, type='mt_text', campaign_id=None, created_at='2024-02-19T11:00:16.743Z', modified_at='2024-02-19T11:00:16.743Z', send_at=None, expire_at='2024-02-22T11:00:16.743Z', callback_url=None, client_reference=None, feedback_enabled=None, flash_message=None)\n",
      "\n",
      "\n",
      "Classes detected: set()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classes detected: set()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classes detected: set()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classes detected: set()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "global base64Frames\n",
    "base64Frames = []\n",
    "\n",
    "if not vid.isOpened():\n",
    "    print(\"Error: Unable to open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to capture frame.\")\n",
    "        break\n",
    "\n",
    "    # Process the frame here (e.g., resize, convert color)\n",
    "    processed_frame = frame  # Replace this with your processing logic\n",
    "\n",
    "    _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "    base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "    \n",
    "    cv2.imshow('frame', processed_frame)\n",
    "    # Save the processed frame as an image file\n",
    "    if len(base64Frames) % 30 == 0:\n",
    "        \n",
    "        directory = \"image\"\n",
    "\n",
    "# Specify the filename of your image\n",
    "        filename = \"temp_frame.jpg\"\n",
    "        # Ensure that the directory exists; if not, create it\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Combine the directory and filename to get the full path of the image\n",
    "        image_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Assuming 'processed_frame' is your image data, save the image\n",
    "        cv2.imwrite(image_path, processed_frame)\n",
    "                \n",
    "        unique_classes = prediction(image_path)\n",
    "    \n",
    "        print(\"Classes detected:\", unique_classes)\n",
    "        print('\\n')\n",
    "        \n",
    "        if 'patient' and 'nurse'  in unique_classes:\n",
    "            print('No SMS')\n",
    "            \n",
    "        elif 'patient' in unique_classes:               \n",
    "            await main()\n",
    "            sms()\n",
    "            time.sleep(1)\n",
    "\n",
    "    if len(base64Frames) % 400 == 0:\n",
    "        del base64Frames[:100]\n",
    "    \n",
    "    elif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('nlp_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a780a905b0354456775c7958e4048b32e96aba80b49847c2bc874b4b77b80e15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
